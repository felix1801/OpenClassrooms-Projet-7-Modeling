{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compte tenu des spécificités de votre problème—données déséquilibrées, coûts de mauvaise classification asymétriques, et un mélange de caractéristiques catégorielles et numériques avec une faible corrélation—je recommande d'utiliser les **Machines à Boosting de Gradient**, spécifiquement **XGBoost** ou **LightGBM**.\n",
    "\n",
    "**Arguments pour ce choix**:\n",
    "\n",
    "- **Performance**: Les GBM surpassent souvent d'autres algorithmes dans les problèmes de données structurées.\n",
    "- **Gestion des données déséquilibrées**: Méthodes intégrées pour gérer le déséquilibre des classes.\n",
    "- **Fonctions de perte personnalisées**: Permettent d'incorporer le ratio de coût 10:1 pour les faux négatifs.\n",
    "- **Importance des caractéristiques**: Fournissent des métriques d'importance des caractéristiques.\n",
    "- **Efficacité**: Efficaces avec de grands ensembles de données.\n",
    "- **Gestion des types de caractéristiques**: Gèrent efficacement les caractéristiques catégorielles et numériques.\n",
    "- **Faible corrélation des caractéristiques**: Moins de problèmes liés à la multicolinéarité.\n",
    "- **Techniques d'atténuation**: Arrêt précoce pour éviter le surapprentissage et les valeurs SHAP ou LIME pour une meilleure interprétabilité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate model selection after first feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, auc, confusion_matrix, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/Z478SG/Desktop/Ecole/OpenClassrooms-Projet-7/modeling/data/03_primary/df_agg.csv'\n",
    "test_size = 0.2\n",
    "random_state = 18\n",
    "cost_fn = 10\n",
    "cost_fp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\2395300263.py:2: DtypeWarning: Columns (756,757,761,762,766,767,771,772,776,777,781,782,786,787,791,792) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = pd.read_csv(data_path)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "raw_data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [re.sub('[^A-Za-z0-9_]+', '', col) for col in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    606\n",
       "bool       133\n",
       "int64       42\n",
       "object      16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour afficher les colonnes de type objet avec plus de 2 valeurs uniques\n",
    "def display_unique_values(df):\n",
    "    obj_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in obj_cols:\n",
    "        unique_values = df[col].nunique()\n",
    "        if unique_values > 2:\n",
    "            print(f\"Colonne: {col}, Valeurs uniques: {df[col].unique()}\")\n",
    "\n",
    "display_unique_values(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n",
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_8288\\3074807741.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(most_frequent_value)\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour convertir les colonnes objet avec 1 à 2 valeurs uniques en booléen ou int\n",
    "def convert_object_columns(df):\n",
    "    obj_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in obj_cols:\n",
    "        # Remplacer les NaN par la valeur la plus représentée\n",
    "        most_frequent_value = df[col].mode()[0]\n",
    "        df[col] = df[col].fillna(most_frequent_value)\n",
    "\n",
    "        unique_values = df[col].nunique()\n",
    "        if unique_values == 1:\n",
    "            df[col] = df[col].astype('bool')\n",
    "        elif unique_values == 2:\n",
    "            df[col] = df[col].astype('category').cat.codes.astype('int8')\n",
    "    return df\n",
    "\n",
    "# Convertir les colonnes objet avec 1 à 2 valeurs uniques en booléen ou int\n",
    "data = convert_object_columns(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour déterminer le type de données approprié\n",
    "def determine_int_type(max_value):\n",
    "    if max_value <= np.iinfo(np.int8).max:\n",
    "        return np.int8\n",
    "    elif max_value <= np.iinfo(np.int16).max:\n",
    "        return np.int16\n",
    "    elif max_value <= np.iinfo(np.int32).max:\n",
    "        return np.int32\n",
    "    else:\n",
    "        return np.int64\n",
    "\n",
    "# Parcourir chaque colonne et convertir le type de données si nécessaire\n",
    "for col in data.select_dtypes(include=[np.int64]).columns:\n",
    "    max_value = data[col].max()\n",
    "    new_type = determine_int_type(max_value)\n",
    "    data[col] = data[col].astype(new_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    606\n",
       "bool       141\n",
       "int8        49\n",
       "int32        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lines with TARGET = NaN\n",
    "data = data.dropna(subset=[\"TARGET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"TARGET\", axis=1)\n",
    "y = data[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST\n",
    "# Séparer les lignes avec TARGET égal à 0 et celles avec TARGET égal à 1\n",
    "df_0 = data[data['TARGET'] == 0]\n",
    "df_1 = data[data['TARGET'] == 1]\n",
    "\n",
    "# Calculer le nombre de lignes nécessaires pour chaque catégorie\n",
    "n_0 = int(1000 * 0.92)  # 92% de 1000\n",
    "n_1 = 1000 - n_0        # 8% de 1000\n",
    "\n",
    "# Sélectionner aléatoirement le nombre approprié de lignes pour chaque catégorie\n",
    "df_0_sampled = df_0.sample(n=n_0, random_state=42)\n",
    "df_1_sampled = df_1.sample(n=n_1, random_state=42)\n",
    "\n",
    "# Concaténer les lignes sélectionnées pour obtenir le DataFrame final\n",
    "df_sampled = pd.concat([df_0_sampled, df_1_sampled])\n",
    "\n",
    "# Mélanger les lignes pour obtenir un DataFrame final aléatoire\n",
    "df_sampled = df_sampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X = df_sampled.drop(\"TARGET\", axis=1)\n",
    "y = df_sampled[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    605\n",
       "bool       141\n",
       "int8        49\n",
       "int32        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print columns types and number of columns in each type\n",
    "X.dtypes.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print columns name that are of type object\n",
    "X.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print columns content that are of type object\n",
    "X.select_dtypes(include='object').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to convert object columns to bool\n",
    "if len(X.select_dtypes(include='object').columns)!=0:\n",
    "    X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    605\n",
       "bool       141\n",
       "int8        49\n",
       "int32        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print columns types and number of columns in each type\n",
    "X.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object columns processed well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process infinit values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_cols_mask = np.isinf(X).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print column names with infinite values\n",
    "inf_cols = X.columns.to_series()[inf_cols_mask].tolist()\n",
    "inf_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print how much rows have infinite values\n",
    "inf_rows_mask = np.isinf(X).any(axis=1)\n",
    "len(X[inf_rows_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the rows that have infinite values\n",
    "X[inf_rows_mask][inf_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: TARGET, dtype: float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print y values on rows where X have inf values\n",
    "y[inf_rows_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in inf_cols:\n",
    "    print(X[col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace inf values with max\n",
    "for col in inf_cols:\n",
    "    if col in X.columns:  # Check if the column exists in the DataFrame\n",
    "        max_value = X[col][X[col] != np.inf].max()  # Get the max value excluding inf\n",
    "        X[col] = X[col].replace([np.inf, -np.inf], max_value)  # Replace inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_cols_mask = np.isinf(X).any()\n",
    "# Print column names with infinite values\n",
    "inf_cols = X.columns.to_series()[inf_cols_mask].tolist()\n",
    "inf_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infinite values processed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to test:\n",
    "- RandomForestClassifier\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "- Logistic Regression avec pondération des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC-ROC: 0.5959485093413666, Std CV AUC-ROC: 0.08054735453519436\n",
      "Test AUC-ROC: 0.6257633032858388\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=random_state,)\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement complet\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les probabilités sur l'ensemble de test\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculer l'AUC-ROC sur l'ensemble de test\n",
    "test_auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Test AUC-ROC: {test_auc_roc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC-ROC: 0.6785258178115321, Std CV AUC-ROC: 0.052833399639566604\n",
      "Test AUC-ROC: 0.5953765629543472\n"
     ]
    }
   ],
   "source": [
    "# XGBoost classifier for binary classification outputing probabilities\n",
    "model = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement complet\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les probabilités sur l'ensemble de test\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculer l'AUC-ROC sur l'ensemble de test\n",
    "test_auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Test AUC-ROC: {test_auc_roc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC-ROC: 0.5279742458313887, Std CV AUC-ROC: 0.02399696604252801\n",
      "Test AUC-ROC: 0.5388194242512357\n"
     ]
    }
   ],
   "source": [
    "# XGBoost classifier for binary classification outputing scores\n",
    "model = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:hinge')\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement complet\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les probabilités sur l'ensemble de test\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculer l'AUC-ROC sur l'ensemble de test\n",
    "test_auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Test AUC-ROC: {test_auc_roc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 48, number of negative: 592\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23321\n",
      "[LightGBM] [Info] Number of data points in the train set: 640, number of used features: 548\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.075000 -> initscore=-2.512306\n",
      "[LightGBM] [Info] Start training from score -2.512306\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 49, number of negative: 591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23273\n",
      "[LightGBM] [Info] Number of data points in the train set: 640, number of used features: 548\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.076563 -> initscore=-2.489996\n",
      "[LightGBM] [Info] Start training from score -2.489996\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 49, number of negative: 591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23024\n",
      "[LightGBM] [Info] Number of data points in the train set: 640, number of used features: 546\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.076563 -> initscore=-2.489996\n",
      "[LightGBM] [Info] Start training from score -2.489996\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 49, number of negative: 591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23262\n",
      "[LightGBM] [Info] Number of data points in the train set: 640, number of used features: 548\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.076563 -> initscore=-2.489996\n",
      "[LightGBM] [Info] Start training from score -2.489996\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 49, number of negative: 591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23421\n",
      "[LightGBM] [Info] Number of data points in the train set: 640, number of used features: 546\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.076563 -> initscore=-2.489996\n",
      "[LightGBM] [Info] Start training from score -2.489996\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Mean CV AUC-ROC: 0.7097617633331919, Std CV AUC-ROC: 0.10045010596465909\n",
      "[LightGBM] [Info] Number of positive: 61, number of negative: 739\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28329\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 551\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.076250 -> initscore=-2.494424\n",
      "[LightGBM] [Info] Start training from score -2.494424\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Test AUC-ROC: 0.6641465542308811\n"
     ]
    }
   ],
   "source": [
    "# LightGBM classifier\n",
    "model = LGBMClassifier(n_estimators=100, random_state=random_state)\n",
    "X_train.columns = [re.sub('[^A-Za-z0-9_]+', '', col) for col in X_train.columns]\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement complet\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les probabilités sur l'ensemble de test\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculer l'AUC-ROC sur l'ensemble de test\n",
    "test_auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Test AUC-ROC: {test_auc_roc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tableau trié par ordre croissant du pourcentage de valeurs manquantes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>SK_ID_CURR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCCUPATION_TYPE_Salesstaff</th>\n",
       "      <td>OCCUPATION_TYPE_Salesstaff</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCCUPATION_TYPE_Secretaries</th>\n",
       "      <td>OCCUPATION_TYPE_Secretaries</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCCUPATION_TYPE_Securitystaff</th>\n",
       "      <td>OCCUPATION_TYPE_Securitystaff</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCCUPATION_TYPE_Waitersbarmenstaff</th>\n",
       "      <td>OCCUPATION_TYPE_Waitersbarmenstaff</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_MEAN</th>\n",
       "      <td>CC_AMT_DRAWINGS_OTHER_CURRENT_MEAN</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_VAR</th>\n",
       "      <td>CC_AMT_DRAWINGS_OTHER_CURRENT_VAR</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_MIN</th>\n",
       "      <td>CC_AMT_DRAWINGS_POS_CURRENT_MIN</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_CNT_DRAWINGS_OTHER_CURRENT_VAR</th>\n",
       "      <td>CC_CNT_DRAWINGS_OTHER_CURRENT_VAR</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_MEAN</th>\n",
       "      <td>CC_CNT_DRAWINGS_POS_CURRENT_MEAN</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Column  \\\n",
       "SK_ID_CURR                                                  SK_ID_CURR   \n",
       "OCCUPATION_TYPE_Salesstaff                  OCCUPATION_TYPE_Salesstaff   \n",
       "OCCUPATION_TYPE_Secretaries                OCCUPATION_TYPE_Secretaries   \n",
       "OCCUPATION_TYPE_Securitystaff            OCCUPATION_TYPE_Securitystaff   \n",
       "OCCUPATION_TYPE_Waitersbarmenstaff  OCCUPATION_TYPE_Waitersbarmenstaff   \n",
       "...                                                                ...   \n",
       "CC_AMT_DRAWINGS_OTHER_CURRENT_MEAN  CC_AMT_DRAWINGS_OTHER_CURRENT_MEAN   \n",
       "CC_AMT_DRAWINGS_OTHER_CURRENT_VAR    CC_AMT_DRAWINGS_OTHER_CURRENT_VAR   \n",
       "CC_AMT_DRAWINGS_POS_CURRENT_MIN        CC_AMT_DRAWINGS_POS_CURRENT_MIN   \n",
       "CC_CNT_DRAWINGS_OTHER_CURRENT_VAR    CC_CNT_DRAWINGS_OTHER_CURRENT_VAR   \n",
       "CC_CNT_DRAWINGS_POS_CURRENT_MEAN      CC_CNT_DRAWINGS_POS_CURRENT_MEAN   \n",
       "\n",
       "                                    Missing Percentage  \n",
       "SK_ID_CURR                                         0.0  \n",
       "OCCUPATION_TYPE_Salesstaff                         0.0  \n",
       "OCCUPATION_TYPE_Secretaries                        0.0  \n",
       "OCCUPATION_TYPE_Securitystaff                      0.0  \n",
       "OCCUPATION_TYPE_Waitersbarmenstaff                 0.0  \n",
       "...                                                ...  \n",
       "CC_AMT_DRAWINGS_OTHER_CURRENT_MEAN                99.3  \n",
       "CC_AMT_DRAWINGS_OTHER_CURRENT_VAR                 99.3  \n",
       "CC_AMT_DRAWINGS_POS_CURRENT_MIN                   99.3  \n",
       "CC_CNT_DRAWINGS_OTHER_CURRENT_VAR                 99.3  \n",
       "CC_CNT_DRAWINGS_POS_CURRENT_MEAN                  99.3  \n",
       "\n",
       "[796 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supposons que X est votre DataFrame\n",
    "missing_percentage = X.isnull().mean() * 100\n",
    "missing_table = pd.DataFrame({'Column': X.columns, 'Missing Percentage': missing_percentage})\n",
    "\n",
    "# Trier par ordre croissant du pourcentage de valeurs manquantes\n",
    "missing_table = missing_table.sort_values(by='Missing Percentage', ascending=True)\n",
    "\n",
    "# Afficher le tableau trié\n",
    "print(\"Tableau trié par ordre croissant du pourcentage de valeurs manquantes:\")\n",
    "missing_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de colonnes avec différents pourcentages de valeurs manquantes:\n",
      ">100%: 0 colonnes\n",
      "90-100%: 131 colonnes\n",
      "75-90%: 36 colonnes\n",
      "50-75%: 100 colonnes\n",
      "25-50%: 312 colonnes\n",
      "<25%: 217 colonnes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compter le nombre de colonnes avec différents pourcentages de valeurs manquantes\n",
    "missing_counts = {\n",
    "    '>100%': (missing_table['Missing Percentage'] == 100).sum(),\n",
    "    '90-100%': ((missing_table['Missing Percentage'] >= 90) & (missing_table['Missing Percentage'] < 100)).sum(),\n",
    "    '75-90%': ((missing_table['Missing Percentage'] >= 75) & (missing_table['Missing Percentage'] < 90)).sum(),\n",
    "    '50-75%': ((missing_table['Missing Percentage'] >= 50) & (missing_table['Missing Percentage'] < 75)).sum(),\n",
    "    '25-50%': ((missing_table['Missing Percentage'] >= 25) & (missing_table['Missing Percentage'] < 50)).sum(),\n",
    "    '<25%': (missing_table['Missing Percentage'] < 25).sum()\n",
    "}\n",
    "\n",
    "# Afficher le nombre de colonnes avec différents pourcentages de valeurs manquantes\n",
    "print(\"\\nNombre de colonnes avec différents pourcentages de valeurs manquantes:\")\n",
    "for key, value in missing_counts.items():\n",
    "    print(f\"{key}: {value} colonnes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les colonnes qui ont plus de 90% de valeurs manquantes\n",
    "columns_to_drop = missing_table[missing_table['Missing Percentage'] > 90]['Column']\n",
    "\n",
    "# Supprimer ces colonnes du DataFrame\n",
    "X_less_na = X.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tableau trié par ordre croissant du pourcentage de valeurs manquantes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>SK_ID_CURR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_WEDNESDAY</th>\n",
       "      <td>WEEKDAY_APPR_PROCESS_START_WEDNESDAY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANIZATION_TYPE_Advertising</th>\n",
       "      <td>ORGANIZATION_TYPE_Advertising</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANIZATION_TYPE_Agriculture</th>\n",
       "      <td>ORGANIZATION_TYPE_Agriculture</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANIZATION_TYPE_Bank</th>\n",
       "      <td>ORGANIZATION_TYPE_Bank</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLOSED_AMT_ANNUITY_MAX</th>\n",
       "      <td>CLOSED_AMT_ANNUITY_MAX</td>\n",
       "      <td>81.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLOSED_AMT_ANNUITY_MEAN</th>\n",
       "      <td>CLOSED_AMT_ANNUITY_MEAN</td>\n",
       "      <td>81.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACTIVE_AMT_ANNUITY_MEAN</th>\n",
       "      <td>ACTIVE_AMT_ANNUITY_MEAN</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACTIVE_AMT_ANNUITY_MAX</th>\n",
       "      <td>ACTIVE_AMT_ANNUITY_MAX</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFUSED_APP_CREDIT_PERC_VAR</th>\n",
       "      <td>REFUSED_APP_CREDIT_PERC_VAR</td>\n",
       "      <td>89.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    Column  \\\n",
       "SK_ID_CURR                                                      SK_ID_CURR   \n",
       "WEEKDAY_APPR_PROCESS_START_WEDNESDAY  WEEKDAY_APPR_PROCESS_START_WEDNESDAY   \n",
       "ORGANIZATION_TYPE_Advertising                ORGANIZATION_TYPE_Advertising   \n",
       "ORGANIZATION_TYPE_Agriculture                ORGANIZATION_TYPE_Agriculture   \n",
       "ORGANIZATION_TYPE_Bank                              ORGANIZATION_TYPE_Bank   \n",
       "...                                                                    ...   \n",
       "CLOSED_AMT_ANNUITY_MAX                              CLOSED_AMT_ANNUITY_MAX   \n",
       "CLOSED_AMT_ANNUITY_MEAN                            CLOSED_AMT_ANNUITY_MEAN   \n",
       "ACTIVE_AMT_ANNUITY_MEAN                            ACTIVE_AMT_ANNUITY_MEAN   \n",
       "ACTIVE_AMT_ANNUITY_MAX                              ACTIVE_AMT_ANNUITY_MAX   \n",
       "REFUSED_APP_CREDIT_PERC_VAR                    REFUSED_APP_CREDIT_PERC_VAR   \n",
       "\n",
       "                                      Missing Percentage  \n",
       "SK_ID_CURR                                           0.0  \n",
       "WEEKDAY_APPR_PROCESS_START_WEDNESDAY                 0.0  \n",
       "ORGANIZATION_TYPE_Advertising                        0.0  \n",
       "ORGANIZATION_TYPE_Agriculture                        0.0  \n",
       "ORGANIZATION_TYPE_Bank                               0.0  \n",
       "...                                                  ...  \n",
       "CLOSED_AMT_ANNUITY_MAX                              81.9  \n",
       "CLOSED_AMT_ANNUITY_MEAN                             81.9  \n",
       "ACTIVE_AMT_ANNUITY_MEAN                             82.0  \n",
       "ACTIVE_AMT_ANNUITY_MAX                              82.0  \n",
       "REFUSED_APP_CREDIT_PERC_VAR                         89.6  \n",
       "\n",
       "[665 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supposons que X est votre DataFrame\n",
    "missing_percentage = X_less_na.isnull().mean() * 100\n",
    "missing_table = pd.DataFrame({'Column': X_less_na.columns, 'Missing Percentage': missing_percentage})\n",
    "\n",
    "# Trier par ordre croissant du pourcentage de valeurs manquantes\n",
    "missing_table = missing_table.sort_values(by='Missing Percentage', ascending=True)\n",
    "\n",
    "# Afficher le tableau trié\n",
    "print(\"Tableau trié par ordre croissant du pourcentage de valeurs manquantes:\")\n",
    "missing_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la moyenne de chaque colonne\n",
    "means = X_less_na.mean()\n",
    "\n",
    "# Remplacer les valeurs manquantes par la moyenne de chaque colonne\n",
    "X_no_na = X_less_na.fillna(means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tableau trié par ordre croissant du pourcentage de valeurs manquantes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>SK_ID_CURR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREV_NAME_CONTRACT_STATUS_nan_MEAN</th>\n",
       "      <td>PREV_NAME_CONTRACT_STATUS_nan_MEAN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREV_NAME_PAYMENT_TYPE_Cashthroughthebank_MEAN</th>\n",
       "      <td>PREV_NAME_PAYMENT_TYPE_Cashthroughthebank_MEAN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREV_NAME_PAYMENT_TYPE_Cashlessfromtheaccountoftheemployer_MEAN</th>\n",
       "      <td>PREV_NAME_PAYMENT_TYPE_Cashlessfromtheaccounto...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREV_NAME_PAYMENT_TYPE_Noncashfromyouraccount_MEAN</th>\n",
       "      <td>PREV_NAME_PAYMENT_TYPE_Noncashfromyouraccount_...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANIZATION_TYPE_University</th>\n",
       "      <td>ORGANIZATION_TYPE_University</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANIZATION_TYPE_XNA</th>\n",
       "      <td>ORGANIZATION_TYPE_XNA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FONDKAPREMONT_MODE_notspecified</th>\n",
       "      <td>FONDKAPREMONT_MODE_notspecified</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FONDKAPREMONT_MODE_regoperaccount</th>\n",
       "      <td>FONDKAPREMONT_MODE_regoperaccount</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n",
       "      <td>CC_NAME_CONTRACT_STATUS_nan_MAX</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               Column  \\\n",
       "SK_ID_CURR                                                                                 SK_ID_CURR   \n",
       "PREV_NAME_CONTRACT_STATUS_nan_MEAN                                 PREV_NAME_CONTRACT_STATUS_nan_MEAN   \n",
       "PREV_NAME_PAYMENT_TYPE_Cashthroughthebank_MEAN         PREV_NAME_PAYMENT_TYPE_Cashthroughthebank_MEAN   \n",
       "PREV_NAME_PAYMENT_TYPE_Cashlessfromtheaccountof...  PREV_NAME_PAYMENT_TYPE_Cashlessfromtheaccounto...   \n",
       "PREV_NAME_PAYMENT_TYPE_Noncashfromyouraccount_MEAN  PREV_NAME_PAYMENT_TYPE_Noncashfromyouraccount_...   \n",
       "...                                                                                               ...   \n",
       "ORGANIZATION_TYPE_University                                             ORGANIZATION_TYPE_University   \n",
       "ORGANIZATION_TYPE_XNA                                                           ORGANIZATION_TYPE_XNA   \n",
       "FONDKAPREMONT_MODE_notspecified                                       FONDKAPREMONT_MODE_notspecified   \n",
       "FONDKAPREMONT_MODE_regoperaccount                                   FONDKAPREMONT_MODE_regoperaccount   \n",
       "CC_NAME_CONTRACT_STATUS_nan_MAX                                       CC_NAME_CONTRACT_STATUS_nan_MAX   \n",
       "\n",
       "                                                    Missing Percentage  \n",
       "SK_ID_CURR                                                         0.0  \n",
       "PREV_NAME_CONTRACT_STATUS_nan_MEAN                                 0.0  \n",
       "PREV_NAME_PAYMENT_TYPE_Cashthroughthebank_MEAN                     0.0  \n",
       "PREV_NAME_PAYMENT_TYPE_Cashlessfromtheaccountof...                 0.0  \n",
       "PREV_NAME_PAYMENT_TYPE_Noncashfromyouraccount_MEAN                 0.0  \n",
       "...                                                                ...  \n",
       "ORGANIZATION_TYPE_University                                       0.0  \n",
       "ORGANIZATION_TYPE_XNA                                              0.0  \n",
       "FONDKAPREMONT_MODE_notspecified                                    0.0  \n",
       "FONDKAPREMONT_MODE_regoperaccount                                  0.0  \n",
       "CC_NAME_CONTRACT_STATUS_nan_MAX                                    0.0  \n",
       "\n",
       "[665 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supposons que X est votre DataFrame\n",
    "missing_percentage = X_no_na.isnull().mean() * 100\n",
    "missing_table = pd.DataFrame({'Column': X_no_na.columns, 'Missing Percentage': missing_percentage})\n",
    "\n",
    "# Trier par ordre croissant du pourcentage de valeurs manquantes\n",
    "missing_table = missing_table.sort_values(by='Missing Percentage', ascending=True)\n",
    "\n",
    "# Afficher le tableau trié\n",
    "print(\"Tableau trié par ordre croissant du pourcentage de valeurs manquantes:\")\n",
    "missing_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_na_train, X_no_na_test, y_train, y_test = train_test_split(X_no_na, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC-ROC: 0.5439901636330207, Std CV AUC-ROC: 0.05880601867420225\n",
      "Test AUC-ROC: 0.523407967432393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression classifier with class weight\n",
    "model = LogisticRegression(class_weight={0: cost_fn, 1: cost_fp}, random_state=random_state, max_iter=1000)\n",
    "cv_scores = cross_val_score(model, X_no_na_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement complet\n",
    "model.fit(X_no_na_train, y_train)\n",
    "\n",
    "# Prédire les probabilités sur l'ensemble de test\n",
    "y_pred_proba = model.predict_proba(X_no_na_test)[:, 1]\n",
    "\n",
    "# Calculer l'AUC-ROC sur l'ensemble de test\n",
    "test_auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Test AUC-ROC: {test_auc_roc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit bien LGBMClassifier qui a le meilleur AUC-ROC : 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
