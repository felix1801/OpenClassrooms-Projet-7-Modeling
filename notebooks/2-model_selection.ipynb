{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compte tenu des spécificités de notre problème—données déséquilibrées, coûts de mauvaise classification asymétriques, et un mélange de caractéristiques catégorielles et numériques avec une faible corrélation—je recommande d'utiliser les **Machines à Boosting de Gradient**, spécifiquement **XGBoost** ou **LightGBM**.\n",
    "\n",
    "**Arguments pour ce choix**:\n",
    "\n",
    "- **Performance**: Les GBM surpassent souvent d'autres algorithmes dans les problèmes de données structurées.\n",
    "- **Gestion des données déséquilibrées**: Méthodes intégrées pour gérer le déséquilibre des classes.\n",
    "- **Fonctions de perte personnalisées**: Permettent d'incorporer le ratio de coût 10:1 pour les faux négatifs.\n",
    "- **Importance des caractéristiques**: Fournissent des métriques d'importance des caractéristiques.\n",
    "- **Efficacité**: Efficaces avec de grands ensembles de données.\n",
    "- **Gestion des types de caractéristiques**: Gèrent efficacement les caractéristiques catégorielles et numériques.\n",
    "- **Faible corrélation des caractéristiques**: Moins de problèmes liés à la multicolinéarité.\n",
    "- **Techniques d'atténuation**: Arrêt précoce pour éviter le surapprentissage et les valeurs SHAP ou LIME pour une meilleure interprétabilité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate model selection after first feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, auc, confusion_matrix, f1_score, precision_score, recall_score\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/Z478SG/Desktop/Ecole/OpenClassrooms-Projet-7/modeling/data/03_primary/df_agg.csv'\n",
    "test_size = 0.2\n",
    "random_state = 18\n",
    "cost_fn = 10\n",
    "cost_fp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lines with TARGET = NaN\n",
    "data = data.dropna(subset=[\"TARGET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    606\n",
       "bool       141\n",
       "int64       50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour déterminer le type de données approprié\n",
    "def determine_int_type(max_value):\n",
    "    if max_value <= np.iinfo(np.int8).max:\n",
    "        return np.int8\n",
    "    elif max_value <= np.iinfo(np.int16).max:\n",
    "        return np.int16\n",
    "    elif max_value <= np.iinfo(np.int32).max:\n",
    "        return np.int32\n",
    "    else:\n",
    "        return np.int64\n",
    "\n",
    "# Parcourir chaque colonne et convertir le type de données si nécessaire\n",
    "for col in data.select_dtypes(include=[np.int64]).columns:\n",
    "    max_value = data[col].max()\n",
    "    new_type = determine_int_type(max_value)\n",
    "    data[col] = data[col].astype(new_type)\n",
    "\n",
    "float64_cols = data.select_dtypes(include=[np.float64]).columns\n",
    "data[float64_cols] = data[float64_cols].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float32    606\n",
       "bool       141\n",
       "int8        49\n",
       "int32        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process infinit values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_cols_mask = np.isinf(data).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print column names with infinite values\n",
    "inf_cols = data.columns.to_series()[inf_cols_mask].tolist()\n",
    "inf_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print how much rows have infinite values\n",
    "inf_rows_mask = np.isinf(data).any(axis=1)\n",
    "len(data[inf_rows_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the rows that have infinite values\n",
    "data[inf_rows_mask][inf_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in inf_cols:\n",
    "    print(data[col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace inf values with max\n",
    "for col in inf_cols:\n",
    "    if col in data.columns:  # Check if the column exists in the DataFrame\n",
    "        max_value = data[col][data[col] != np.inf].max()  # Get the max value excluding inf\n",
    "        data[col] = data[col].replace([np.inf, -np.inf], max_value)  # Replace inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_cols_mask = np.isinf(data).any()\n",
    "# Print column names with infinite values\n",
    "inf_cols = data.columns.to_series()[inf_cols_mask].tolist()\n",
    "inf_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infinite values processed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"TARGET\", axis=1)\n",
    "y = data[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TEST\n",
    "# # Séparer les lignes avec TARGET égal à 0 et celles avec TARGET égal à 1\n",
    "# df_0 = data[data['TARGET'] == 0]\n",
    "# df_1 = data[data['TARGET'] == 1]\n",
    "\n",
    "# # Calculer le nombre de lignes nécessaires pour chaque catégorie\n",
    "# n_0 = int(1000 * 0.92)  # 92% de 1000\n",
    "# n_1 = 1000 - n_0        # 8% de 1000\n",
    "\n",
    "# # Sélectionner aléatoirement le nombre approprié de lignes pour chaque catégorie\n",
    "# df_0_sampled = df_0.sample(n=n_0, random_state=42)\n",
    "# df_1_sampled = df_1.sample(n=n_1, random_state=42)\n",
    "\n",
    "# # Concaténer les lignes sélectionnées pour obtenir le DataFrame final\n",
    "# df_sampled = pd.concat([df_0_sampled, df_1_sampled])\n",
    "\n",
    "# # Mélanger les lignes pour obtenir un DataFrame final aléatoire\n",
    "# df_sampled = df_sampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# X = df_sampled.drop(\"TARGET\", axis=1)\n",
    "# y = df_sampled[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307507, 796)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to test:\n",
    "- RandomForestClassifier\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "- Logistic Regression avec pondération des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/08 21:53:06 INFO mlflow.tracking.fluent: Experiment with name 'OCR7' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/Z478SG/Desktop/Ecole/OpenClassrooms-Projet-7/modeling/mlruns/842049509272676280', creation_time=1733691186762, experiment_id='842049509272676280', last_update_time=1733691186762, lifecycle_stage='active', name='OCR7', tags={}>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(uri=\"file:///C:/Users/Z478SG/Desktop/Ecole/OpenClassrooms-Projet-7/modeling/mlruns\")\n",
    "mlflow.set_experiment(\"OCR7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_metrics(model_name, features, metrics):\n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"num_features\", len(features))\n",
    "        mlflow.log_param(\"features\", features)\n",
    "        mlflow.log_metric(\"AUC-ROC\", metrics['auc-roc'])\n",
    "        mlflow.log_metric(\"F1\", metrics['f1'])\n",
    "        mlflow.log_metric(\"Precision\", metrics['precision'])\n",
    "        mlflow.log_metric(\"Recall\", metrics['recall'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model(y_pred_proba, y_test, threshold=0.5):\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "    return {\n",
    "        'auc-roc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC-ROC: 0.6822085250052969, Std CV AUC-ROC: 0.0028411781978164162\n",
      "Test AUC-ROC: 0.6910631117285699\n",
      "Test F1: 0.0\n",
      "Test Precision: 0.0\n",
      "Test Recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/08 22:53:11 WARNING mlflow.utils.validation: Param value '['SK_ID_CURR', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',...' (26333 characters) is truncated to 6000 characters to meet the length limit.\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=random_state,)\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement complet\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les probabilités sur l'ensemble de test\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics = assess_model(y_pred_proba, y_test)\n",
    "print(f\"Test AUC-ROC: {metrics['auc-roc']}\")\n",
    "print(f\"Test F1: {metrics['f1']}\")\n",
    "print(f\"Test Precision: {metrics['precision']}\")\n",
    "print(f\"Test Recall: {metrics['recall']}\")\n",
    "\n",
    "log_model_metrics('RandomForestClassifier', X_train.columns.tolist(), metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test AUC-ROC: 0.6910631117285699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC-ROC: 0.6926229244684583, Std CV AUC-ROC: 0.002501769040956962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/12/08 22:54:26 WARNING mlflow.utils.validation: Param value '['SK_ID_CURR', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',...' (26333 characters) is truncated to 6000 characters to meet the length limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC-ROC: 0.6912438237237336\n",
      "Test F1: 0.0\n",
      "Test Precision: 0.0\n",
      "Test Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "# XGBoost classifier for binary classification outputing probabilities\n",
    "model = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement complet\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les probabilités sur l'ensemble de test\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculer les métriques sur l'ensemble de test\n",
    "metrics = assess_model(y_pred_proba, y_test)\n",
    "print(f\"Test AUC-ROC: {metrics['auc-roc']}\")\n",
    "print(f\"Test F1: {metrics['f1']}\")\n",
    "print(f\"Test Precision: {metrics['precision']}\")\n",
    "print(f\"Test Recall: {metrics['recall']}\")\n",
    "\n",
    "log_model_metrics('XGBClassifier', X_train.columns.tolist(), metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test AUC-ROC: 0.6912438237237336\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC-ROC: 0.5, Std CV AUC-ROC: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/12/08 22:55:55 WARNING mlflow.utils.validation: Param value '['SK_ID_CURR', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',...' (26333 characters) is truncated to 6000 characters to meet the length limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC-ROC: 0.5\n",
      "Test F1: 0.0\n",
      "Test Precision: 0.0\n",
      "Test Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "# XGBoost classifier for binary classification outputing scores\n",
    "model = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:hinge')\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement complet\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les probabilités sur l'ensemble de test\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics = assess_model(y_pred_proba, y_test)\n",
    "print(f\"Test AUC-ROC: {metrics['auc-roc']}\")\n",
    "print(f\"Test F1: {metrics['f1']}\")\n",
    "print(f\"Test Precision: {metrics['precision']}\")\n",
    "print(f\"Test Recall: {metrics['recall']}\")\n",
    "\n",
    "log_model_metrics('XGBClassifier-binary:hinge', X_train.columns.tolist(), metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test AUC-ROC: 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15956, number of negative: 180848\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.980974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 92971\n",
      "[LightGBM] [Info] Number of data points in the train set: 196804, number of used features: 772\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081076 -> initscore=-2.427822\n",
      "[LightGBM] [Info] Start training from score -2.427822\n",
      "[LightGBM] [Info] Number of positive: 15956, number of negative: 180848\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.346470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 93095\n",
      "[LightGBM] [Info] Number of data points in the train set: 196804, number of used features: 772\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081076 -> initscore=-2.427822\n",
      "[LightGBM] [Info] Start training from score -2.427822\n",
      "[LightGBM] [Info] Number of positive: 15956, number of negative: 180848\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.938529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 93107\n",
      "[LightGBM] [Info] Number of data points in the train set: 196804, number of used features: 773\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081076 -> initscore=-2.427822\n",
      "[LightGBM] [Info] Start training from score -2.427822\n",
      "[LightGBM] [Info] Number of positive: 15956, number of negative: 180848\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.875202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 93117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196804, number of used features: 772\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081076 -> initscore=-2.427822\n",
      "[LightGBM] [Info] Start training from score -2.427822\n",
      "[LightGBM] [Info] Number of positive: 15956, number of negative: 180848\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.286933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 92953\n",
      "[LightGBM] [Info] Number of data points in the train set: 196804, number of used features: 772\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081076 -> initscore=-2.427822\n",
      "[LightGBM] [Info] Start training from score -2.427822\n",
      "Mean CV AUC-ROC: 0.7561559550198063, Std CV AUC-ROC: 0.0009305049909370441\n",
      "[LightGBM] [Info] Number of positive: 19945, number of negative: 226060\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.365904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 93013\n",
      "[LightGBM] [Info] Number of data points in the train set: 246005, number of used features: 774\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081076 -> initscore=-2.427822\n",
      "[LightGBM] [Info] Start training from score -2.427822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/08 22:58:52 WARNING mlflow.utils.validation: Param value '['SK_ID_CURR', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',...' (26333 characters) is truncated to 6000 characters to meet the length limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC-ROC: 0.7606255692770754\n",
      "Test F1: 0.0406231512522185\n",
      "Test Precision: 0.5392670157068062\n",
      "Test Recall: 0.02110655737704918\n"
     ]
    }
   ],
   "source": [
    "# LightGBM classifier\n",
    "model = LGBMClassifier(n_estimators=100, random_state=random_state)\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement complet\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les probabilités sur l'ensemble de test\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics = assess_model(y_pred_proba, y_test)\n",
    "print(f\"Test AUC-ROC: {metrics['auc-roc']}\")\n",
    "print(f\"Test F1: {metrics['f1']}\")\n",
    "print(f\"Test Precision: {metrics['precision']}\")\n",
    "print(f\"Test Recall: {metrics['recall']}\")\n",
    "\n",
    "log_model_metrics('LGBMClassifier', X_train.columns.tolist(), metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test AUC-ROC: 0.7606255692770754\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tableau trié par ordre croissant du pourcentage de valeurs manquantes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>SK_ID_CURR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCCUPATION_TYPE_Privateservicestaff</th>\n",
       "      <td>OCCUPATION_TYPE_Privateservicestaff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCCUPATION_TYPE_Realtyagents</th>\n",
       "      <td>OCCUPATION_TYPE_Realtyagents</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCCUPATION_TYPE_Salesstaff</th>\n",
       "      <td>OCCUPATION_TYPE_Salesstaff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCCUPATION_TYPE_Secretaries</th>\n",
       "      <td>OCCUPATION_TYPE_Secretaries</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_VAR</th>\n",
       "      <td>CC_CNT_DRAWINGS_POS_CURRENT_VAR</td>\n",
       "      <td>99.318064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_VAR</th>\n",
       "      <td>CC_AMT_DRAWINGS_ATM_CURRENT_VAR</td>\n",
       "      <td>99.318064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_VAR</th>\n",
       "      <td>CC_CNT_DRAWINGS_ATM_CURRENT_VAR</td>\n",
       "      <td>99.318064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_VAR</th>\n",
       "      <td>CC_AMT_DRAWINGS_POS_CURRENT_VAR</td>\n",
       "      <td>99.318064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_VAR</th>\n",
       "      <td>CC_AMT_PAYMENT_CURRENT_VAR</td>\n",
       "      <td>99.318390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  Column  \\\n",
       "SK_ID_CURR                                                    SK_ID_CURR   \n",
       "OCCUPATION_TYPE_Privateservicestaff  OCCUPATION_TYPE_Privateservicestaff   \n",
       "OCCUPATION_TYPE_Realtyagents                OCCUPATION_TYPE_Realtyagents   \n",
       "OCCUPATION_TYPE_Salesstaff                    OCCUPATION_TYPE_Salesstaff   \n",
       "OCCUPATION_TYPE_Secretaries                  OCCUPATION_TYPE_Secretaries   \n",
       "...                                                                  ...   \n",
       "CC_CNT_DRAWINGS_POS_CURRENT_VAR          CC_CNT_DRAWINGS_POS_CURRENT_VAR   \n",
       "CC_AMT_DRAWINGS_ATM_CURRENT_VAR          CC_AMT_DRAWINGS_ATM_CURRENT_VAR   \n",
       "CC_CNT_DRAWINGS_ATM_CURRENT_VAR          CC_CNT_DRAWINGS_ATM_CURRENT_VAR   \n",
       "CC_AMT_DRAWINGS_POS_CURRENT_VAR          CC_AMT_DRAWINGS_POS_CURRENT_VAR   \n",
       "CC_AMT_PAYMENT_CURRENT_VAR                    CC_AMT_PAYMENT_CURRENT_VAR   \n",
       "\n",
       "                                     Missing Percentage  \n",
       "SK_ID_CURR                                     0.000000  \n",
       "OCCUPATION_TYPE_Privateservicestaff            0.000000  \n",
       "OCCUPATION_TYPE_Realtyagents                   0.000000  \n",
       "OCCUPATION_TYPE_Salesstaff                     0.000000  \n",
       "OCCUPATION_TYPE_Secretaries                    0.000000  \n",
       "...                                                 ...  \n",
       "CC_CNT_DRAWINGS_POS_CURRENT_VAR               99.318064  \n",
       "CC_AMT_DRAWINGS_ATM_CURRENT_VAR               99.318064  \n",
       "CC_CNT_DRAWINGS_ATM_CURRENT_VAR               99.318064  \n",
       "CC_AMT_DRAWINGS_POS_CURRENT_VAR               99.318064  \n",
       "CC_AMT_PAYMENT_CURRENT_VAR                    99.318390  \n",
       "\n",
       "[796 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supposons que X est votre DataFrame\n",
    "missing_percentage = X.isnull().mean() * 100\n",
    "missing_table = pd.DataFrame({'Column': X.columns, 'Missing Percentage': missing_percentage})\n",
    "\n",
    "# Trier par ordre croissant du pourcentage de valeurs manquantes\n",
    "missing_table = missing_table.sort_values(by='Missing Percentage', ascending=True)\n",
    "\n",
    "# Afficher le tableau trié\n",
    "print(\"Tableau trié par ordre croissant du pourcentage de valeurs manquantes:\")\n",
    "missing_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de colonnes avec différents pourcentages de valeurs manquantes:\n",
      ">100%: 0 colonnes\n",
      "90-100%: 125 colonnes\n",
      "75-90%: 42 colonnes\n",
      "50-75%: 80 colonnes\n",
      "25-50%: 332 colonnes\n",
      "<25%: 217 colonnes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compter le nombre de colonnes avec différents pourcentages de valeurs manquantes\n",
    "missing_counts = {\n",
    "    '>100%': (missing_table['Missing Percentage'] == 100).sum(),\n",
    "    '90-100%': ((missing_table['Missing Percentage'] >= 90) & (missing_table['Missing Percentage'] < 100)).sum(),\n",
    "    '75-90%': ((missing_table['Missing Percentage'] >= 75) & (missing_table['Missing Percentage'] < 90)).sum(),\n",
    "    '50-75%': ((missing_table['Missing Percentage'] >= 50) & (missing_table['Missing Percentage'] < 75)).sum(),\n",
    "    '25-50%': ((missing_table['Missing Percentage'] >= 25) & (missing_table['Missing Percentage'] < 50)).sum(),\n",
    "    '<25%': (missing_table['Missing Percentage'] < 25).sum()\n",
    "}\n",
    "\n",
    "# Afficher le nombre de colonnes avec différents pourcentages de valeurs manquantes\n",
    "print(\"\\nNombre de colonnes avec différents pourcentages de valeurs manquantes:\")\n",
    "for key, value in missing_counts.items():\n",
    "    print(f\"{key}: {value} colonnes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les colonnes qui ont plus de 90% de valeurs manquantes\n",
    "columns_to_drop = missing_table[missing_table['Missing Percentage'] > 90]['Column']\n",
    "\n",
    "# Supprimer ces colonnes du DataFrame\n",
    "X_less_na = X.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tableau trié par ordre croissant du pourcentage de valeurs manquantes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>SK_ID_CURR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_THURSDAY</th>\n",
       "      <td>WEEKDAY_APPR_PROCESS_START_THURSDAY</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_TUESDAY</th>\n",
       "      <td>WEEKDAY_APPR_PROCESS_START_TUESDAY</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_WEDNESDAY</th>\n",
       "      <td>WEEKDAY_APPR_PROCESS_START_WEDNESDAY</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANIZATION_TYPE_Advertising</th>\n",
       "      <td>ORGANIZATION_TYPE_Advertising</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFUSED_AMT_DOWN_PAYMENT_MIN</th>\n",
       "      <td>REFUSED_AMT_DOWN_PAYMENT_MIN</td>\n",
       "      <td>89.549181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFUSED_AMT_DOWN_PAYMENT_MEAN</th>\n",
       "      <td>REFUSED_AMT_DOWN_PAYMENT_MEAN</td>\n",
       "      <td>89.549181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFUSED_RATE_DOWN_PAYMENT_MEAN</th>\n",
       "      <td>REFUSED_RATE_DOWN_PAYMENT_MEAN</td>\n",
       "      <td>89.549181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFUSED_RATE_DOWN_PAYMENT_MIN</th>\n",
       "      <td>REFUSED_RATE_DOWN_PAYMENT_MIN</td>\n",
       "      <td>89.549181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFUSED_AMT_DOWN_PAYMENT_MAX</th>\n",
       "      <td>REFUSED_AMT_DOWN_PAYMENT_MAX</td>\n",
       "      <td>89.549181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    Column  \\\n",
       "SK_ID_CURR                                                      SK_ID_CURR   \n",
       "WEEKDAY_APPR_PROCESS_START_THURSDAY    WEEKDAY_APPR_PROCESS_START_THURSDAY   \n",
       "WEEKDAY_APPR_PROCESS_START_TUESDAY      WEEKDAY_APPR_PROCESS_START_TUESDAY   \n",
       "WEEKDAY_APPR_PROCESS_START_WEDNESDAY  WEEKDAY_APPR_PROCESS_START_WEDNESDAY   \n",
       "ORGANIZATION_TYPE_Advertising                ORGANIZATION_TYPE_Advertising   \n",
       "...                                                                    ...   \n",
       "REFUSED_AMT_DOWN_PAYMENT_MIN                  REFUSED_AMT_DOWN_PAYMENT_MIN   \n",
       "REFUSED_AMT_DOWN_PAYMENT_MEAN                REFUSED_AMT_DOWN_PAYMENT_MEAN   \n",
       "REFUSED_RATE_DOWN_PAYMENT_MEAN              REFUSED_RATE_DOWN_PAYMENT_MEAN   \n",
       "REFUSED_RATE_DOWN_PAYMENT_MIN                REFUSED_RATE_DOWN_PAYMENT_MIN   \n",
       "REFUSED_AMT_DOWN_PAYMENT_MAX                  REFUSED_AMT_DOWN_PAYMENT_MAX   \n",
       "\n",
       "                                      Missing Percentage  \n",
       "SK_ID_CURR                                      0.000000  \n",
       "WEEKDAY_APPR_PROCESS_START_THURSDAY             0.000000  \n",
       "WEEKDAY_APPR_PROCESS_START_TUESDAY              0.000000  \n",
       "WEEKDAY_APPR_PROCESS_START_WEDNESDAY            0.000000  \n",
       "ORGANIZATION_TYPE_Advertising                   0.000000  \n",
       "...                                                  ...  \n",
       "REFUSED_AMT_DOWN_PAYMENT_MIN                   89.549181  \n",
       "REFUSED_AMT_DOWN_PAYMENT_MEAN                  89.549181  \n",
       "REFUSED_RATE_DOWN_PAYMENT_MEAN                 89.549181  \n",
       "REFUSED_RATE_DOWN_PAYMENT_MIN                  89.549181  \n",
       "REFUSED_AMT_DOWN_PAYMENT_MAX                   89.549181  \n",
       "\n",
       "[671 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supposons que X est votre DataFrame\n",
    "missing_percentage = X_less_na.isnull().mean() * 100\n",
    "missing_table = pd.DataFrame({'Column': X_less_na.columns, 'Missing Percentage': missing_percentage})\n",
    "\n",
    "# Trier par ordre croissant du pourcentage de valeurs manquantes\n",
    "missing_table = missing_table.sort_values(by='Missing Percentage', ascending=True)\n",
    "\n",
    "# Afficher le tableau trié\n",
    "print(\"Tableau trié par ordre croissant du pourcentage de valeurs manquantes:\")\n",
    "missing_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la moyenne de chaque colonne\n",
    "means = X_less_na.mean()\n",
    "\n",
    "# Remplacer les valeurs manquantes par la moyenne de chaque colonne\n",
    "X_no_na = X_less_na.fillna(means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tableau trié par ordre croissant du pourcentage de valeurs manquantes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>SK_ID_CURR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREV_NAME_PAYMENT_TYPE_XNA_MEAN</th>\n",
       "      <td>PREV_NAME_PAYMENT_TYPE_XNA_MEAN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREV_NAME_PAYMENT_TYPE_nan_MEAN</th>\n",
       "      <td>PREV_NAME_PAYMENT_TYPE_nan_MEAN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREV_CODE_REJECT_REASON_CLIENT_MEAN</th>\n",
       "      <td>PREV_CODE_REJECT_REASON_CLIENT_MEAN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREV_CODE_REJECT_REASON_HC_MEAN</th>\n",
       "      <td>PREV_CODE_REJECT_REASON_HC_MEAN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FONDKAPREMONT_MODE_notspecified</th>\n",
       "      <td>FONDKAPREMONT_MODE_notspecified</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FONDKAPREMONT_MODE_orgspecaccount</th>\n",
       "      <td>FONDKAPREMONT_MODE_orgspecaccount</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FONDKAPREMONT_MODE_regoperaccount</th>\n",
       "      <td>FONDKAPREMONT_MODE_regoperaccount</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSETYPE_MODE_blockofflats</th>\n",
       "      <td>HOUSETYPE_MODE_blockofflats</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n",
       "      <td>CC_NAME_CONTRACT_STATUS_nan_MAX</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  Column  \\\n",
       "SK_ID_CURR                                                    SK_ID_CURR   \n",
       "PREV_NAME_PAYMENT_TYPE_XNA_MEAN          PREV_NAME_PAYMENT_TYPE_XNA_MEAN   \n",
       "PREV_NAME_PAYMENT_TYPE_nan_MEAN          PREV_NAME_PAYMENT_TYPE_nan_MEAN   \n",
       "PREV_CODE_REJECT_REASON_CLIENT_MEAN  PREV_CODE_REJECT_REASON_CLIENT_MEAN   \n",
       "PREV_CODE_REJECT_REASON_HC_MEAN          PREV_CODE_REJECT_REASON_HC_MEAN   \n",
       "...                                                                  ...   \n",
       "FONDKAPREMONT_MODE_notspecified          FONDKAPREMONT_MODE_notspecified   \n",
       "FONDKAPREMONT_MODE_orgspecaccount      FONDKAPREMONT_MODE_orgspecaccount   \n",
       "FONDKAPREMONT_MODE_regoperaccount      FONDKAPREMONT_MODE_regoperaccount   \n",
       "HOUSETYPE_MODE_blockofflats                  HOUSETYPE_MODE_blockofflats   \n",
       "CC_NAME_CONTRACT_STATUS_nan_MAX          CC_NAME_CONTRACT_STATUS_nan_MAX   \n",
       "\n",
       "                                     Missing Percentage  \n",
       "SK_ID_CURR                                          0.0  \n",
       "PREV_NAME_PAYMENT_TYPE_XNA_MEAN                     0.0  \n",
       "PREV_NAME_PAYMENT_TYPE_nan_MEAN                     0.0  \n",
       "PREV_CODE_REJECT_REASON_CLIENT_MEAN                 0.0  \n",
       "PREV_CODE_REJECT_REASON_HC_MEAN                     0.0  \n",
       "...                                                 ...  \n",
       "FONDKAPREMONT_MODE_notspecified                     0.0  \n",
       "FONDKAPREMONT_MODE_orgspecaccount                   0.0  \n",
       "FONDKAPREMONT_MODE_regoperaccount                   0.0  \n",
       "HOUSETYPE_MODE_blockofflats                         0.0  \n",
       "CC_NAME_CONTRACT_STATUS_nan_MAX                     0.0  \n",
       "\n",
       "[671 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supposons que X est votre DataFrame\n",
    "missing_percentage = X_no_na.isnull().mean() * 100\n",
    "missing_table = pd.DataFrame({'Column': X_no_na.columns, 'Missing Percentage': missing_percentage})\n",
    "\n",
    "# Trier par ordre croissant du pourcentage de valeurs manquantes\n",
    "missing_table = missing_table.sort_values(by='Missing Percentage', ascending=True)\n",
    "\n",
    "# Afficher le tableau trié\n",
    "print(\"Tableau trié par ordre croissant du pourcentage de valeurs manquantes:\")\n",
    "missing_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_na_train, X_no_na_test, y_train, y_test = train_test_split(X_no_na, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC-ROC: 0.5242008662812383, Std CV AUC-ROC: 0.00430157480949822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/12/08 23:32:28 WARNING mlflow.utils.validation: Param value '['SK_ID_CURR', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',...' (26333 characters) is truncated to 6000 characters to meet the length limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC-ROC: 0.5286756624749345\n",
      "Test F1: 0.0\n",
      "Test Precision: 0.0\n",
      "Test Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression classifier with class weight\n",
    "model = LogisticRegression(class_weight={0: cost_fn, 1: cost_fp}, random_state=random_state, max_iter=1000)\n",
    "cv_scores = cross_val_score(model, X_no_na_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement complet\n",
    "model.fit(X_no_na_train, y_train)\n",
    "\n",
    "# Prédire les probabilités sur l'ensemble de test\n",
    "y_pred_proba = model.predict_proba(X_no_na_test)[:, 1]\n",
    "\n",
    "metrics = assess_model(y_pred_proba, y_test)\n",
    "print(f\"Test AUC-ROC: {metrics['auc-roc']}\")\n",
    "print(f\"Test F1: {metrics['f1']}\")\n",
    "print(f\"Test Precision: {metrics['precision']}\")\n",
    "print(f\"Test Recall: {metrics['recall']}\")\n",
    "\n",
    "log_model_metrics('LogisticRegression', X_train.columns.tolist(), metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test AUC-ROC: 0.5286756624749345\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit bien LGBMClassifier qui a le meilleur AUC-ROC : 0.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
