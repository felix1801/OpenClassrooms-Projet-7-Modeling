{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.3.0 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('C:/Users/Z478SG/Desktop/Ecole/OpenClassrooms-Projet-7/modeling/data/06_models/lightgbm_model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/Z478SG/Desktop/Ecole/OpenClassrooms-Projet-7/modeling/data/03_primary/df_agg.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Local\\Temp\\ipykernel_11288\\560202589.py:1: DtypeWarning: Columns (756,757,761,762,766,767,771,772,776,777,781,782,786,787,791,792) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(data_path)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_NAME_CONTRACT_STATUS_Active_MIN\n",
      "CC_NAME_CONTRACT_STATUS_Active_MAX\n",
      "CC_NAME_CONTRACT_STATUS_Approved_MIN\n",
      "CC_NAME_CONTRACT_STATUS_Approved_MAX\n",
      "CC_NAME_CONTRACT_STATUS_Completed_MIN\n",
      "CC_NAME_CONTRACT_STATUS_Completed_MAX\n",
      "CC_NAME_CONTRACT_STATUS_Demand_MIN\n",
      "CC_NAME_CONTRACT_STATUS_Demand_MAX\n",
      "CC_NAME_CONTRACT_STATUS_Refused_MIN\n",
      "CC_NAME_CONTRACT_STATUS_Refused_MAX\n",
      "CC_NAME_CONTRACT_STATUS_Sent proposal_MIN\n",
      "CC_NAME_CONTRACT_STATUS_Sent proposal_MAX\n",
      "CC_NAME_CONTRACT_STATUS_Signed_MIN\n",
      "CC_NAME_CONTRACT_STATUS_Signed_MAX\n",
      "CC_NAME_CONTRACT_STATUS_nan_MIN\n",
      "CC_NAME_CONTRACT_STATUS_nan_MAX\n"
     ]
    }
   ],
   "source": [
    "columns_to_remove = []\n",
    "\n",
    "for col in data.columns:\n",
    "    if data[col].dtype=='object':\n",
    "        print(col)\n",
    "        columns_to_remove.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=columns_to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356251, 781)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    if data[col].dtype=='object':\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_CURR                              int64\n",
       "TARGET                                float64\n",
       "CODE_GENDER                             int64\n",
       "FLAG_OWN_CAR                            int64\n",
       "FLAG_OWN_REALTY                         int64\n",
       "                                       ...   \n",
       "CC_NAME_CONTRACT_STATUS_Signed_VAR    float64\n",
       "CC_NAME_CONTRACT_STATUS_nan_MEAN      float64\n",
       "CC_NAME_CONTRACT_STATUS_nan_SUM       float64\n",
       "CC_NAME_CONTRACT_STATUS_nan_VAR       float64\n",
       "CC_COUNT                              float64\n",
       "Length: 781, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "C:\\Users\\Z478SG\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    }
   ],
   "source": [
    "data = data.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_CURR                            float16\n",
       "TARGET                                float16\n",
       "CODE_GENDER                           float16\n",
       "FLAG_OWN_CAR                          float16\n",
       "FLAG_OWN_REALTY                       float16\n",
       "                                       ...   \n",
       "CC_NAME_CONTRACT_STATUS_Signed_VAR    float16\n",
       "CC_NAME_CONTRACT_STATUS_nan_MEAN      float16\n",
       "CC_NAME_CONTRACT_STATUS_nan_SUM       float16\n",
       "CC_NAME_CONTRACT_STATUS_nan_VAR       float16\n",
       "CC_COUNT                              float16\n",
       "Length: 781, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data['TARGET'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307507, 781)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoir train_data avec la même quantité de 0 ou de 1. Et regarder si proba tjrs pareil ou pas\n",
    "\n",
    "# voir si y'a aussi cette erreur sur l'ancien notebook\n",
    "\n",
    "# Faire tourner un autre modèle que LGBX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 781)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data[:10000]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
    "y = train_data['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91466421, 0.08533579],\n",
       "       [0.91988249, 0.08011751],\n",
       "       [0.91986139, 0.08013861],\n",
       "       ...,\n",
       "       [0.91713096, 0.08286904],\n",
       "       [0.91665911, 0.08334089],\n",
       "       [0.91622034, 0.08377966]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1: Prédire les probabilités\n",
    "proba_predictions = model.predict_proba(X)[:, 1]  # Prendre la probabilité de la classe 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.07976982829029503\n",
      "Mean: 0.08081596845173342\n",
      "Max: 0.08813962971194243\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min: {proba_predictions.min()}\")\n",
    "print(f\"Mean: {proba_predictions.mean()}\")\n",
    "print(f\"Max: {proba_predictions.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 2: Appliquer un seuil pour convertir les probabilités en prédictions binaires\n",
    "def apply_threshold(proba_predictions, threshold):\n",
    "    return (proba_predictions >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 3: Évaluer la précision du modèle\n",
    "def evaluate_model(y_true, proba_predictions, threshold):\n",
    "    binary_predictions = apply_threshold(proba_predictions, threshold)\n",
    "    accuracy = accuracy_score(y_true, binary_predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle avec un seuil de 0.8: 0.9225\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "threshold = 0.8  # Vous pouvez ajuster ce seuil manuellement\n",
    "accuracy = evaluate_model(y, proba_predictions, threshold)\n",
    "print(f\"Précision du modèle avec un seuil de {threshold}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle avec un seuil de 0.79: 0.9225\n",
      "Précision du modèle avec un seuil de 0.8: 0.9225\n",
      "Précision du modèle avec un seuil de 0.81: 0.9225\n",
      "Précision du modèle avec un seuil de 0.8200000000000001: 0.9225\n",
      "Précision du modèle avec un seuil de 0.8300000000000001: 0.9225\n",
      "Précision du modèle avec un seuil de 0.8400000000000001: 0.9225\n",
      "Précision du modèle avec un seuil de 0.8500000000000001: 0.9225\n",
      "Précision du modèle avec un seuil de 0.8600000000000001: 0.9225\n",
      "Précision du modèle avec un seuil de 0.8700000000000001: 0.9225\n",
      "Précision du modèle avec un seuil de 0.8800000000000001: 0.9225\n"
     ]
    }
   ],
   "source": [
    "# Pour tester différents seuils\n",
    "thresholds = np.arange(0.79, 0.89, 0.01)\n",
    "for threshold in thresholds:\n",
    "    accuracy = evaluate_model(y, proba_predictions, threshold)\n",
    "    print(f\"Précision du modèle avec un seuil de {threshold}: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
