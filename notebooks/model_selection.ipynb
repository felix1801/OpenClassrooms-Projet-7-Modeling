{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, auc, confusion_matrix, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/03_primary/processed_data.csv'\n",
    "artifact_path = \"../data/06_models/\"\n",
    "test_size = 0.2\n",
    "random_state = 18\n",
    "cost_fn = 10\n",
    "cost_fp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = pd.read_csv(data_path)\n",
    "raw_data = raw_data.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data[['SK_ID_CURR', 'PAYMENT_RATE', 'EXT_SOURCE_3', 'EXT_SOURCE_2', 'DAYS_BIRTH', 'EXT_SOURCE_1', 'DAYS_EMPLOYED', 'DAYS_EMPLOYED_PERC', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'ANNUITY_INCOME_PERC', 'INSTAL_DBD_MEAN', 'AMT_ANNUITY', 'TARGET']].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove lines with TARGET = NaN\n",
    "data = data.dropna(subset=[\"TARGET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"TARGET\", axis=1)\n",
    "y = data[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"random_state\": random_state,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set grid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to test:\n",
    "- RandomForestClassifier\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "- Logistic Regression avec pondÃ©ration des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC-ROC: 0.7141470598822511, Std CV AUC-ROC: 0.003167640807687861\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=random_state,)\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC-ROC: 0.6926229244684583, Std CV AUC-ROC: 0.002501769040956962\n"
     ]
    }
   ],
   "source": [
    "# XGBoost classifier for binary classification outputing probabilities\n",
    "model = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC-ROC: 0.5, Std CV AUC-ROC: 0.0\n"
     ]
    }
   ],
   "source": [
    "# XGBoost classifier for binary classification outputing scores\n",
    "model = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:hinge')\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15956, number of negative: 180848\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3315\n",
      "[LightGBM] [Info] Number of data points in the train set: 196804, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081076 -> initscore=-2.427822\n",
      "[LightGBM] [Info] Start training from score -2.427822\n",
      "[LightGBM] [Info] Number of positive: 15956, number of negative: 180848\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3315\n",
      "[LightGBM] [Info] Number of data points in the train set: 196804, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081076 -> initscore=-2.427822\n",
      "[LightGBM] [Info] Start training from score -2.427822\n",
      "[LightGBM] [Info] Number of positive: 15956, number of negative: 180848\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3315\n",
      "[LightGBM] [Info] Number of data points in the train set: 196804, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081076 -> initscore=-2.427822\n",
      "[LightGBM] [Info] Start training from score -2.427822\n",
      "[LightGBM] [Info] Number of positive: 15956, number of negative: 180848\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3315\n",
      "[LightGBM] [Info] Number of data points in the train set: 196804, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081076 -> initscore=-2.427822\n",
      "[LightGBM] [Info] Start training from score -2.427822\n",
      "[LightGBM] [Info] Number of positive: 15956, number of negative: 180848\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3315\n",
      "[LightGBM] [Info] Number of data points in the train set: 196804, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081076 -> initscore=-2.427822\n",
      "[LightGBM] [Info] Start training from score -2.427822\n",
      "Mean CV AUC-ROC: 0.7544479685542389, Std CV AUC-ROC: 0.0007425640795959872\n"
     ]
    }
   ],
   "source": [
    "# LightGBM classifier\n",
    "model = LGBMClassifier(n_estimators=100, random_state=random_state)\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>SK_ID_CURR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYMENT_RATE</th>\n",
       "      <td>PAYMENT_RATE</td>\n",
       "      <td>0.003902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>19.825565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>0.214629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <td>DAYS_BIRTH</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <td>EXT_SOURCE_1</td>\n",
       "      <td>56.381156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <td>DAYS_EMPLOYED</td>\n",
       "      <td>18.007395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <td>DAYS_EMPLOYED_PERC</td>\n",
       "      <td>18.007395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <td>DAYS_REGISTRATION</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <td>DAYS_ID_PUBLISH</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANNUITY_INCOME_PERC</th>\n",
       "      <td>ANNUITY_INCOME_PERC</td>\n",
       "      <td>0.003902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTAL_DBD_MEAN</th>\n",
       "      <td>INSTAL_DBD_MEAN</td>\n",
       "      <td>5.160208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <td>AMT_ANNUITY</td>\n",
       "      <td>0.003902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TARGET</th>\n",
       "      <td>TARGET</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Column  Missing Percentage\n",
       "SK_ID_CURR                    SK_ID_CURR            0.000000\n",
       "PAYMENT_RATE                PAYMENT_RATE            0.003902\n",
       "EXT_SOURCE_3                EXT_SOURCE_3           19.825565\n",
       "EXT_SOURCE_2                EXT_SOURCE_2            0.214629\n",
       "DAYS_BIRTH                    DAYS_BIRTH            0.000000\n",
       "EXT_SOURCE_1                EXT_SOURCE_1           56.381156\n",
       "DAYS_EMPLOYED              DAYS_EMPLOYED           18.007395\n",
       "DAYS_EMPLOYED_PERC    DAYS_EMPLOYED_PERC           18.007395\n",
       "DAYS_REGISTRATION      DAYS_REGISTRATION            0.000000\n",
       "DAYS_ID_PUBLISH          DAYS_ID_PUBLISH            0.000000\n",
       "ANNUITY_INCOME_PERC  ANNUITY_INCOME_PERC            0.003902\n",
       "INSTAL_DBD_MEAN          INSTAL_DBD_MEAN            5.160208\n",
       "AMT_ANNUITY                  AMT_ANNUITY            0.003902\n",
       "TARGET                            TARGET            0.000000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = data.isnull().mean() * 100\n",
    "missing_table = pd.DataFrame({'Column': data.columns, 'Missing Percentage': missing_percentage})\n",
    "missing_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    134131.000000\n",
       "mean          0.502129\n",
       "std           0.211061\n",
       "min           0.014568\n",
       "25%           0.334007\n",
       "50%           0.505998\n",
       "75%           0.675057\n",
       "max           0.962693\n",
       "Name: EXT_SOURCE_1, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EXT_SOURCE_1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    246542.000000\n",
       "mean          0.510856\n",
       "std           0.194831\n",
       "min           0.000527\n",
       "25%           0.370650\n",
       "50%           0.535276\n",
       "75%           0.669057\n",
       "max           0.896010\n",
       "Name: EXT_SOURCE_3, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EXT_SOURCE_3'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    252133.000000\n",
       "mean      -2384.142334\n",
       "std        2338.247559\n",
       "min      -17912.000000\n",
       "25%       -3175.000000\n",
       "50%       -1648.000000\n",
       "75%        -767.000000\n",
       "max           0.000000\n",
       "Name: DAYS_EMPLOYED, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DAYS_EMPLOYED'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    291639.000000\n",
       "mean         12.265641\n",
       "std           9.142044\n",
       "min           0.000000\n",
       "25%           6.672414\n",
       "50%          10.119047\n",
       "75%          15.138889\n",
       "max         295.000000\n",
       "Name: INSTAL_DBD_MEAN, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['INSTAL_DBD_MEAN'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_na = data.dropna(subset=['PAYMENT_RATE', 'ANNUITY_INCOME_PERC', 'EXT_SOURCE_2', 'AMT_ANNUITY'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_na.loc[:, 'INSTAL_DBD_MEAN'] = data_no_na['INSTAL_DBD_MEAN'].fillna(data_no_na['INSTAL_DBD_MEAN'].mean())\n",
    "data_no_na.loc[:, 'EXT_SOURCE_3'] = data_no_na['EXT_SOURCE_3'].fillna(data_no_na['EXT_SOURCE_3'].mean())\n",
    "data_no_na.loc[:, 'EXT_SOURCE_1'] = data_no_na['EXT_SOURCE_1'].fillna(data_no_na['EXT_SOURCE_1'].mean())\n",
    "data_no_na.loc[:, 'DAYS_EMPLOYED'] = data_no_na['DAYS_EMPLOYED'].fillna(data_no_na['DAYS_EMPLOYED'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_na = data_no_na.drop('DAYS_EMPLOYED_PERC', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>SK_ID_CURR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYMENT_RATE</th>\n",
       "      <td>PAYMENT_RATE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <td>DAYS_BIRTH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <td>EXT_SOURCE_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <td>DAYS_EMPLOYED</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <td>DAYS_REGISTRATION</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <td>DAYS_ID_PUBLISH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANNUITY_INCOME_PERC</th>\n",
       "      <td>ANNUITY_INCOME_PERC</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTAL_DBD_MEAN</th>\n",
       "      <td>INSTAL_DBD_MEAN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <td>AMT_ANNUITY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TARGET</th>\n",
       "      <td>TARGET</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Column  Missing Percentage\n",
       "SK_ID_CURR                    SK_ID_CURR                 0.0\n",
       "PAYMENT_RATE                PAYMENT_RATE                 0.0\n",
       "EXT_SOURCE_3                EXT_SOURCE_3                 0.0\n",
       "EXT_SOURCE_2                EXT_SOURCE_2                 0.0\n",
       "DAYS_BIRTH                    DAYS_BIRTH                 0.0\n",
       "EXT_SOURCE_1                EXT_SOURCE_1                 0.0\n",
       "DAYS_EMPLOYED              DAYS_EMPLOYED                 0.0\n",
       "DAYS_REGISTRATION      DAYS_REGISTRATION                 0.0\n",
       "DAYS_ID_PUBLISH          DAYS_ID_PUBLISH                 0.0\n",
       "ANNUITY_INCOME_PERC  ANNUITY_INCOME_PERC                 0.0\n",
       "INSTAL_DBD_MEAN          INSTAL_DBD_MEAN                 0.0\n",
       "AMT_ANNUITY                  AMT_ANNUITY                 0.0\n",
       "TARGET                            TARGET                 0.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage = data_no_na.isnull().mean() * 100\n",
    "missing_table = pd.DataFrame({'Column': data_no_na.columns, 'Missing Percentage': missing_percentage})\n",
    "missing_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_na = data_no_na.drop(\"TARGET\", axis=1)\n",
    "y_no_na = data_no_na[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_na_train, X_no_na_test, y_no_na_train, y_no_na_test = train_test_split(X_no_na, y_no_na, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV AUC-ROC: 0.721595330445109, Std CV AUC-ROC: 0.005410793566440281\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression classifier with class weight\n",
    "model = LogisticRegression(class_weight={0: cost_fn, 1: cost_fp}, random_state=random_state, max_iter=1000)\n",
    "cv_scores = cross_val_score(model, X_no_na_train, y_no_na_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Mean CV AUC-ROC: {np.mean(cv_scores)}, Std CV AUC-ROC: {np.std(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit LGBMClassifier qui a le meilleur AUC-ROC : 0.75"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
